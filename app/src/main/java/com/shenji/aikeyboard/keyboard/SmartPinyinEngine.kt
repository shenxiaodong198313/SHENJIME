package com.shenji.aikeyboard.keyboard

import android.util.LruCache
import com.shenji.aikeyboard.data.trie.TrieManager
import com.shenji.aikeyboard.data.trie.TrieType
import com.shenji.aikeyboard.model.WordFrequency
// import com.shenji.aikeyboard.data.repository.DictionaryRepository
import kotlinx.coroutines.*
import timber.log.Timber
import java.util.concurrent.atomic.AtomicLong
import kotlin.system.measureTimeMillis

/**
 * æ™ºèƒ½æ‹¼éŸ³å¼•æ“ - é¡¹ç›®ä¸­å”¯ä¸€çš„å€™é€‰è¯æŸ¥è¯¢å¼•æ“
 * 
 * è®¾è®¡åŸåˆ™ï¼š
 * 1. åªå¤„ç†å½“å‰æ­£åœ¨è¾“å…¥çš„æ‹¼éŸ³éƒ¨åˆ†ï¼ˆä¸åŒ…æ‹¬å·²ç¡®è®¤æ–‡æœ¬ï¼‰
 * 2. æ ¹æ®è¾“å…¥é•¿åº¦å’ŒçŠ¶æ€é€‰æ‹©æœ€ä¼˜æŸ¥è¯¢ç­–ç•¥
 * 3. åˆ©ç”¨TrieåŠ è½½çŠ¶æ€è¿›è¡Œæ™ºèƒ½è·¯ç”±
 * 4. æ¸è¿›å¼æŸ¥è¯¢ï¼Œé¿å…é‡å¤è®¡ç®—
 * 5. ç»Ÿä¸€çš„éŸ³èŠ‚åŒ¹é…ã€æ‹†åˆ†ã€æŸ¥è¯¢æ–¹æ³•
 */
class SmartPinyinEngine private constructor() {
    
    private val trieManager = TrieManager.instance
    // private val dictionaryRepository = DictionaryRepository.getInstance()
    
    // æ¸è¿›å¼ç¼“å­˜ - ç¼“å­˜ç”¨æˆ·è¾“å…¥è¿‡ç¨‹ä¸­çš„ç»“æœ
    private val progressiveCache = LruCache<String, CachedResult>(200)
    
    // æ€§èƒ½ç»Ÿè®¡
    private val queryCount = AtomicLong(0)
    private val cacheHits = AtomicLong(0)
    private val totalQueryTime = AtomicLong(0)
    
    companion object {
        @Volatile
        private var INSTANCE: SmartPinyinEngine? = null
        
        fun getInstance(): SmartPinyinEngine {
            return INSTANCE ?: synchronized(this) {
                INSTANCE ?: SmartPinyinEngine().also { INSTANCE = it }
            }
        }
    }
    
    /**
     * ç¼“å­˜ç»“æœæ•°æ®ç±»
     */
    private data class CachedResult(
        val candidates: List<WordFrequency>,
        val analysis: QueryAnalysis,
        val timestamp: Long = System.currentTimeMillis()
    )
    
    /**
     * æŸ¥è¯¢åˆ†ææ•°æ®ç±»
     */
    data class QueryAnalysis(
        val inputType: InputType,
        val queryStrategy: QueryStrategy,
        val segmentations: List<String>,
        val trieStatus: String,
        val queryTime: Long,
        val resultCount: Int,
        val cacheHit: Boolean
    )
    
    /**
     * è¾“å…¥ç±»å‹æšä¸¾
     */
    enum class InputType {
        SINGLE_CHAR,        // å•å­—ç¬¦: "n", "w"
        SHORT_INPUT,        // çŸ­è¾“å…¥: "ni", "wo", "nh"
        MEDIUM_INPUT,       // ä¸­ç­‰è¾“å…¥: "nihao", "nhao"
        LONG_INPUT,         // é•¿è¾“å…¥: "woshibeijingren"
        MIXED_INPUT         // æ··åˆè¾“å…¥: "wodepy", "woshibjr"
    }
    
    /**
     * æŸ¥è¯¢ç­–ç•¥æšä¸¾
     */
    enum class QueryStrategy {
        CHAR_TRIE_ONLY,     // ä»…æŸ¥è¯¢å•å­—Trie
        TRIE_PRIORITY,      // Trieä¼˜å…ˆ
        HYBRID_QUERY,       // æ··åˆæŸ¥è¯¢
        DATABASE_PRIORITY,  // æ•°æ®åº“ä¼˜å…ˆ
        PROGRESSIVE_FILTER, // æ¸è¿›å¼è¿‡æ»¤
        ABBREVIATION_MATCH  // ç¼©å†™åŒ¹é…
    }
    
    /**
     * ä¸»è¦æŸ¥è¯¢æ¥å£ - è·å–å€™é€‰è¯ï¼ˆæ”¯æŒæ™ºèƒ½åˆ†å±‚æ‡’åŠ è½½ï¼‰
     */
    suspend fun getCandidates(currentPinyin: String, limit: Int = 25, offset: Int = 0): List<WordFrequency> {
        if (currentPinyin.isBlank()) return emptyList()
        
        val cleanInput = currentPinyin.trim().lowercase()
        queryCount.incrementAndGet()
        
        var queryTime = 0L
        val result = measureTimeMillis {
            // 1. æ£€æŸ¥æ¸è¿›å¼ç¼“å­˜
            val cachedResult = checkProgressiveCache(cleanInput)
            if (cachedResult != null) {
                cacheHits.incrementAndGet()
                // æ”¯æŒæ™ºèƒ½åˆ†å±‚åˆ†é¡µè¿”å›
                return getLayeredCandidates(cleanInput, cachedResult.candidates, limit, offset)
            }
            
            // 2. åˆ†æè¾“å…¥ç±»å‹
            val inputType = analyzeInputType(cleanInput)
            
            // 3. é€‰æ‹©æŸ¥è¯¢ç­–ç•¥
            val strategy = selectQueryStrategy(inputType, cleanInput)
            
            // 4. æ‰§è¡Œå…¨é‡æŸ¥è¯¢ï¼ˆä¸ºåˆ†å±‚æ‡’åŠ è½½å‡†å¤‡ï¼‰
            val candidates = executeFullQuery(cleanInput, strategy)
            
            // 5. ç¼“å­˜ç»“æœ
            val analysis = QueryAnalysis(
                inputType = inputType,
                queryStrategy = strategy,
                segmentations = generateSegmentations(cleanInput),
                trieStatus = getTrieStatus(),
                queryTime = queryTime,
                resultCount = candidates.size,
                cacheHit = false
            )
            
            progressiveCache.put(cleanInput, CachedResult(candidates, analysis))
            
        }.let { queryTime = it; progressiveCache.get(cleanInput)?.candidates ?: emptyList() }
        
        totalQueryTime.addAndGet(queryTime)
        
        // è¿”å›æ™ºèƒ½åˆ†å±‚ç»“æœ
        return getLayeredCandidates(cleanInput, result, limit, offset)
    }
    
    /**
     * æ™ºèƒ½åˆ†å±‚å€™é€‰è¯è·å–
     * 
     * åˆ†å±‚ç­–ç•¥ï¼š
     * 1. ç¬¬1å±‚ï¼šä¸éŸ³èŠ‚æ•°ç›¸åŒçš„è¯ç»„ï¼ˆæŒ‰è¯é¢‘æ’åºï¼‰
     * 2. ç¬¬2å±‚ï¼šç¬¬1ä¸ªéŸ³èŠ‚çš„å•å­—å€™é€‰
     * 3. ç¬¬3å±‚ï¼šç¬¬2ä¸ªéŸ³èŠ‚çš„å•å­—å€™é€‰
     * 4. ç¬¬Nå±‚ï¼šç¬¬Nä¸ªéŸ³èŠ‚çš„å•å­—å€™é€‰
     */
    private suspend fun getLayeredCandidates(
        input: String, 
        allCandidates: List<WordFrequency>, 
        limit: Int, 
        offset: Int
    ): List<WordFrequency> {
        // è·å–éŸ³èŠ‚åˆ†å‰²
        val segments = intelligentSegmentation(input)
        val segmentCount = segments.size
        
        // æ„å»ºåˆ†å±‚å€™é€‰è¯
        val layeredCandidates = buildLayeredCandidates(input, segments, allCandidates)
        
        // åˆ†é¡µè¿”å›
        val startIndex = offset
        val endIndex = minOf(offset + limit, layeredCandidates.size)
        return if (startIndex < layeredCandidates.size) {
            layeredCandidates.subList(startIndex, endIndex)
        } else {
            emptyList()
        }
    }
    
    /**
     * æ„å»ºåˆ†å±‚å€™é€‰è¯åˆ—è¡¨
     */
    private suspend fun buildLayeredCandidates(
        input: String,
        segments: List<String>,
        allCandidates: List<WordFrequency>
    ): List<WordFrequency> {
        val layeredResults = mutableListOf<WordFrequency>()
        val segmentCount = segments.size
        
        Timber.d("æ„å»ºåˆ†å±‚å€™é€‰è¯: $input -> ${segments.joinToString(" ")} (${segmentCount}ä¸ªéŸ³èŠ‚)")
        
        // ç¬¬1å±‚ï¼šä¸éŸ³èŠ‚æ•°ç›¸åŒçš„è¯ç»„
        if (segmentCount >= 2) {
            val matchingLengthWords = allCandidates.filter { it.word.length == segmentCount }
                .sortedByDescending { it.frequency }
            layeredResults.addAll(matchingLengthWords)
            Timber.d("ç¬¬1å±‚(${segmentCount}å­—è¯): ${matchingLengthWords.size}ä¸ª")
        } else {
            // å•éŸ³èŠ‚è¾“å…¥ï¼Œç›´æ¥æ·»åŠ æ‰€æœ‰å€™é€‰
            layeredResults.addAll(allCandidates.sortedByDescending { it.frequency })
        }
        
        // ç¬¬2-Nå±‚ï¼šæŒ‰éŸ³èŠ‚é¡ºåºçš„å•å­—å€™é€‰
        if (segmentCount >= 2) {
            for ((index, segment) in segments.withIndex()) {
                val singleCharCandidates = getSingleCharCandidates(segment)
                    .filter { candidate -> 
                        // é¿å…é‡å¤æ·»åŠ å·²æœ‰çš„å€™é€‰è¯
                        !layeredResults.any { it.word == candidate.word }
                    }
                    .sortedByDescending { it.frequency }
                
                layeredResults.addAll(singleCharCandidates)
                Timber.d("ç¬¬${index + 2}å±‚(${segment}å•å­—): ${singleCharCandidates.size}ä¸ª")
            }
        }
        
        return layeredResults.distinctBy { it.word }
    }
    
    /**
     * è·å–å•ä¸ªéŸ³èŠ‚çš„å•å­—å€™é€‰
     */
    private suspend fun getSingleCharCandidates(segment: String): List<WordFrequency> {
        val results = mutableListOf<WordFrequency>()
        
        // æŸ¥è¯¢å•å­—Trie
        if (trieManager.isTrieLoaded(TrieType.CHARS)) {
            val charResults = trieManager.searchByPrefix(TrieType.CHARS, segment, 20)
            results.addAll(charResults)
        }
        
        // æŸ¥è¯¢BASE Trieä¸­çš„å•å­—
        if (trieManager.isTrieLoaded(TrieType.BASE)) {
            val baseResults = trieManager.searchByPrefix(TrieType.BASE, segment, 15)
                .filter { it.word.length == 1 }
            results.addAll(baseResults)
        }
        
        return results.distinctBy { it.word }
    }
    
    /**
     * æ‰§è¡Œå…¨é‡æŸ¥è¯¢ï¼ˆä¸ºåˆ†å±‚æ‡’åŠ è½½å‡†å¤‡æ‰€æœ‰å€™é€‰è¯ï¼‰
     */
    private suspend fun executeFullQuery(input: String, strategy: QueryStrategy): List<WordFrequency> {
        return when (strategy) {
            QueryStrategy.CHAR_TRIE_ONLY -> queryCharTrieOnly(input, 100)
            QueryStrategy.TRIE_PRIORITY -> queryTriePriority(input, 200)
            QueryStrategy.HYBRID_QUERY -> queryHybridFull(input)
            QueryStrategy.DATABASE_PRIORITY -> queryDatabasePriority(input, 300)
            QueryStrategy.PROGRESSIVE_FILTER -> queryProgressiveFilter(input, 200)
            QueryStrategy.ABBREVIATION_MATCH -> queryAbbreviationMatchFull(input)
        }
    }
    
    /**
     * æ··åˆæŸ¥è¯¢ - å…¨é‡ç‰ˆæœ¬ï¼ˆä¸ºæ‡’åŠ è½½å‡†å¤‡ï¼‰
     */
    private suspend fun queryHybridFull(input: String): List<WordFrequency> {
        return withContext(Dispatchers.Default) {
            val results = mutableListOf<WordFrequency>()
            
            // 1. è·å–æ‰€æœ‰å¯èƒ½çš„åˆ†å‰²æ–¹æ¡ˆ
            val segmentations = generateSegmentations(input)
            
            // 2. å¯¹æ¯ç§åˆ†å‰²æ–¹æ¡ˆè¿›è¡Œå…¨é‡æŸ¥è¯¢
            for (segmentation in segmentations) {
                val segments = if (segmentation.contains(" ")) {
                    segmentation.split(" ")
                } else {
                    listOf(segmentation)
                }
                
                if (segments.size > 1) {
                    // å¤šéŸ³èŠ‚ï¼šæŸ¥è¯¢æ‰€æœ‰å¯èƒ½çš„è¯ç»„
                    val phraseResults = queryAllPhrases(segments)
                    results.addAll(phraseResults)
                } else {
                    // å•éŸ³èŠ‚ï¼šæŸ¥è¯¢æ‰€æœ‰ç›¸å…³å€™é€‰
                    val singleResults = querySingleSegment(segments[0], 100)
                    results.addAll(singleResults)
                }
            }
            
            results.distinctBy { it.word }
                .sortedByDescending { it.frequency }
        }
    }
    
    /**
     * æŸ¥è¯¢æ‰€æœ‰å¯èƒ½çš„è¯ç»„
     */
    private suspend fun queryAllPhrases(segments: List<String>): List<WordFrequency> {
        val results = mutableListOf<WordFrequency>()
        val segmentCount = segments.size
        
        // æŸ¥è¯¢ä¸éŸ³èŠ‚æ•°ç›¸åŒçš„è¯ç»„
        val fullPhrase = segments.joinToString("")
        if (trieManager.isTrieLoaded(TrieType.BASE)) {
            val fullPhraseResults = trieManager.searchByPrefix(TrieType.BASE, fullPhrase, 100)
                .filter { it.word.length == segmentCount }
            results.addAll(fullPhraseResults)
        }
        
        // æŸ¥è¯¢è¾ƒçŸ­çš„è¯ç»„ç»„åˆ
        for (phraseLength in (segmentCount - 1) downTo 2) {
            for (startIndex in 0..(segmentCount - phraseLength)) {
                val phraseSegments = segments.subList(startIndex, startIndex + phraseLength)
                val phrase = phraseSegments.joinToString("")
                
                if (trieManager.isTrieLoaded(TrieType.BASE)) {
                    val phraseResults = trieManager.searchByPrefix(TrieType.BASE, phrase, 50)
                        .filter { it.word.length == phraseLength }
                    results.addAll(phraseResults)
                }
            }
        }
        
        return results
    }
    
    /**
     * ç¼©å†™åŒ¹é… - å…¨é‡ç‰ˆæœ¬
     */
    private suspend fun queryAbbreviationMatchFull(input: String): List<WordFrequency> {
        return withContext(Dispatchers.Default) {
            val results = mutableListOf<WordFrequency>()
            
            // æŸ¥è¯¢æ‰€æœ‰ç›¸å…³çš„è¯ç»„å’Œå•å­—
            val firstChar = input.first().toString()
            
            // æŸ¥è¯¢è¯ç»„
            if (trieManager.isTrieLoaded(TrieType.BASE)) {
                val phraseResults = trieManager.searchByPrefix(TrieType.BASE, firstChar, 200)
                results.addAll(phraseResults)
                
                if (input.length > 1) {
                    val fullResults = trieManager.searchByPrefix(TrieType.BASE, input, 100)
                    results.addAll(fullResults)
                }
            }
            
            // æŸ¥è¯¢å•å­—
            if (trieManager.isTrieLoaded(TrieType.CHARS)) {
                val charResults = trieManager.searchByPrefix(TrieType.CHARS, firstChar, 50)
                results.addAll(charResults)
            }
            
            results.distinctBy { it.word }
                .sortedByDescending { it.frequency }
        }
    }
    
    /**
     * è·å–æ›´å¤šå€™é€‰è¯ï¼ˆæ‡’åŠ è½½æ¥å£ï¼‰
     */
    suspend fun getMoreCandidates(currentPinyin: String, currentCount: Int, batchSize: Int = 25): List<WordFrequency> {
        return getCandidates(currentPinyin, batchSize, currentCount)
    }
    
    /**
     * æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æ›´å¤šå€™é€‰è¯
     */
    suspend fun hasMoreCandidates(currentPinyin: String, currentCount: Int): Boolean {
        if (currentPinyin.isBlank()) return false
        
        val cleanInput = currentPinyin.trim().lowercase()
        val cachedResult = checkProgressiveCache(cleanInput)
        
        return if (cachedResult != null) {
            currentCount < cachedResult.candidates.size
        } else {
            // å¦‚æœæ²¡æœ‰ç¼“å­˜ï¼Œå‡è®¾å¯èƒ½æœ‰æ›´å¤šï¼ˆéœ€è¦å®é™…æŸ¥è¯¢éªŒè¯ï¼‰
            true
        }
    }
    
    /**
     * è·å–æŸ¥è¯¢åˆ†æä¿¡æ¯
     */
    suspend fun getQueryAnalysis(currentPinyin: String): QueryAnalysis {
        if (currentPinyin.isBlank()) {
            return QueryAnalysis(
                InputType.SINGLE_CHAR, QueryStrategy.CHAR_TRIE_ONLY, 
                emptyList(), getTrieStatus(), 0, 0, false
            )
        }
        
        val cleanInput = currentPinyin.trim().lowercase()
        
        // æ£€æŸ¥ç¼“å­˜
        val cached = progressiveCache.get(cleanInput)
        if (cached != null) {
            return cached.analysis.copy(cacheHit = true)
        }
        
        // é‡æ–°åˆ†æ
        val inputType = analyzeInputType(cleanInput)
        val strategy = selectQueryStrategy(inputType, cleanInput)
        
        return QueryAnalysis(
            inputType = inputType,
            queryStrategy = strategy,
            segmentations = generateSegmentations(cleanInput),
            trieStatus = getTrieStatus(),
            queryTime = 0,
            resultCount = 0,
            cacheHit = false
        )
    }
    
    /**
     * åˆ†æè¾“å…¥ç±»å‹
     */
    private fun analyzeInputType(input: String): InputType {
        return when {
            input.length == 1 -> InputType.SINGLE_CHAR
            input.length <= 3 -> {
                // æ£€æŸ¥æ˜¯å¦ä¸ºç¼©å†™æ¨¡å¼
                if (isAbbreviationPattern(input)) {
                    InputType.SHORT_INPUT
                } else {
                    InputType.SHORT_INPUT
                }
            }
            input.length <= 6 -> {
                // æ£€æŸ¥æ˜¯å¦ä¸ºæ··åˆè¾“å…¥ï¼ˆç¼©å†™+éŸ³èŠ‚ï¼‰
                if (isMixedInput(input)) {
                    InputType.MIXED_INPUT
                } else {
                    InputType.MEDIUM_INPUT
                }
            }
            input.length <= 12 -> InputType.LONG_INPUT
            else -> InputType.MIXED_INPUT
        }
    }
    
    /**
     * åˆ¤æ–­æ˜¯å¦ä¸ºæ··åˆè¾“å…¥ï¼ˆç¼©å†™+éŸ³èŠ‚ç»„åˆï¼‰
     */
    private fun isMixedInput(input: String): Boolean {
        // å°è¯•æ‰¾åˆ°æœ‰æ•ˆçš„æ‹¼éŸ³éŸ³èŠ‚åˆ†å‰²
        val segments = intelligentSegmentation(input)
        return segments.size > 1 && segments.any { it.length == 1 } && segments.any { it.length > 1 }
    }
    
    /**
     * é€‰æ‹©æŸ¥è¯¢ç­–ç•¥
     */
    private fun selectQueryStrategy(inputType: InputType, input: String): QueryStrategy {
        return when (inputType) {
            InputType.SINGLE_CHAR -> {
                QueryStrategy.CHAR_TRIE_ONLY
            }
            InputType.SHORT_INPUT -> {
                // æ£€æŸ¥æ˜¯å¦ä¸ºç¼©å†™æ¨¡å¼ï¼ˆ2-4ä¸ªè¾…éŸ³å­—æ¯ï¼‰
                if (isAbbreviationPattern(input)) {
                    QueryStrategy.ABBREVIATION_MATCH
                } else if (trieManager.isTrieLoaded(TrieType.BASE)) {
                    QueryStrategy.TRIE_PRIORITY
                } else {
                    QueryStrategy.DATABASE_PRIORITY
                }
            }
            InputType.MEDIUM_INPUT -> {
                // æ£€æŸ¥æ˜¯å¦æœ‰å‰ç¼€ç¼“å­˜å¯ä»¥åˆ©ç”¨
                if (hasProgressivePrefix(input)) {
                    QueryStrategy.PROGRESSIVE_FILTER
                } else {
                    QueryStrategy.HYBRID_QUERY
                }
            }
            InputType.MIXED_INPUT -> {
                QueryStrategy.HYBRID_QUERY
            }
            InputType.LONG_INPUT -> {
                QueryStrategy.DATABASE_PRIORITY
            }
        }
    }
    
    /**
     * æ‰§è¡ŒæŸ¥è¯¢
     */
    private suspend fun executeQuery(input: String, strategy: QueryStrategy, limit: Int): List<WordFrequency> {
        return when (strategy) {
            QueryStrategy.CHAR_TRIE_ONLY -> queryCharTrieOnly(input, limit)
            QueryStrategy.TRIE_PRIORITY -> queryTriePriority(input, limit)
            QueryStrategy.HYBRID_QUERY -> queryHybrid(input, limit)
            QueryStrategy.DATABASE_PRIORITY -> queryDatabasePriority(input, limit)
            QueryStrategy.PROGRESSIVE_FILTER -> queryProgressiveFilter(input, limit)
            QueryStrategy.ABBREVIATION_MATCH -> queryAbbreviationMatch(input, limit)
        }
    }
    
    /**
     * ä»…æŸ¥è¯¢å•å­—Trie
     */
    private suspend fun queryCharTrieOnly(input: String, limit: Int): List<WordFrequency> {
        return withContext(Dispatchers.Default) {
            if (trieManager.isTrieLoaded(TrieType.CHARS)) {
                trieManager.searchByPrefix(TrieType.CHARS, input, limit)
            } else {
                // å¦‚æœå•å­—TrieæœªåŠ è½½ï¼Œè¿”å›ç©ºåˆ—è¡¨
                emptyList()
            }
        }
    }
    
    /**
     * Trieä¼˜å…ˆæŸ¥è¯¢
     */
    private suspend fun queryTriePriority(input: String, limit: Int): List<WordFrequency> {
        return withContext(Dispatchers.Default) {
            val results = mutableListOf<WordFrequency>()
            
            // 1. æŸ¥è¯¢å•å­—Trie
            if (trieManager.isTrieLoaded(TrieType.CHARS)) {
                results.addAll(trieManager.searchByPrefix(TrieType.CHARS, input, 3))
            }
            
            // 2. æŸ¥è¯¢åŸºç¡€Trie
            if (trieManager.isTrieLoaded(TrieType.BASE) && results.size < limit) {
                results.addAll(trieManager.searchByPrefix(TrieType.BASE, input, limit - results.size))
            }
            
            // 3. å¦‚æœç»“æœä¸è¶³ï¼Œæš‚æ—¶è·³è¿‡æ•°æ®åº“æŸ¥è¯¢
            // if (results.size < limit / 2) {
            //     results.addAll(dictionaryRepository.searchByPinyin(input, limit - results.size))
            // }
            
            results.distinctBy { it.word }.take(limit)
        }
    }
    
    /**
     * æ··åˆæŸ¥è¯¢ - å®ç°åˆ†å±‚å€™é€‰è¯ç­–ç•¥ï¼Œæ”¯æŒå£°æ¯æ­§ä¹‰æ€§
     */
    private suspend fun queryHybrid(input: String, limit: Int): List<WordFrequency> {
        return withContext(Dispatchers.Default) {
            val results = mutableListOf<WordFrequency>()
            
            // 1. è·å–æ‰€æœ‰å¯èƒ½çš„åˆ†å‰²æ–¹æ¡ˆ
            val segmentations = generateSegmentations(input)
            
            // 2. å¯¹æ¯ç§åˆ†å‰²æ–¹æ¡ˆè¿›è¡ŒæŸ¥è¯¢
            for (segmentation in segmentations) {
                if (results.size >= limit) break
                
                val segments = if (segmentation.contains(" ")) {
                    segmentation.split(" ")
                } else {
                    listOf(segmentation)
                }
                
                if (segments.size > 1) {
                    // å¤šéŸ³èŠ‚ï¼šä½¿ç”¨åˆ†å±‚æŸ¥è¯¢ç­–ç•¥
                    val layeredResults = queryLayeredCandidates(segments, limit / segmentations.size)
                    results.addAll(layeredResults)
                } else {
                    // å•éŸ³èŠ‚ï¼šç›´æ¥æŸ¥è¯¢
                    val singleResults = querySingleSegment(segments[0], limit / segmentations.size)
                    results.addAll(singleResults)
                }
            }
            
            results.distinctBy { it.word }
                .sortedByDescending { it.frequency }
                .take(limit)
        }
    }
    
    /**
     * æŸ¥è¯¢å•ä¸ªéŸ³èŠ‚
     */
    private suspend fun querySingleSegment(segment: String, limit: Int): List<WordFrequency> {
        val results = mutableListOf<WordFrequency>()
        
        // æŸ¥è¯¢BASE Trie
        if (trieManager.isTrieLoaded(TrieType.BASE)) {
            results.addAll(trieManager.searchByPrefix(TrieType.BASE, segment, limit))
        }
        
        // æŸ¥è¯¢å•å­—Trie
        if (trieManager.isTrieLoaded(TrieType.CHARS)) {
            results.addAll(trieManager.searchByPrefix(TrieType.CHARS, segment, limit / 2))
        }
        
        return results.take(limit)
    }
    
    /**
     * åˆ†å±‚å€™é€‰è¯æŸ¥è¯¢ç­–ç•¥ - ä¼˜åŒ–ç‰ˆ
     * 
     * ç­–ç•¥è¯´æ˜ï¼š
     * 1. ä¸¥æ ¼æŒ‰éŸ³èŠ‚æ•°ä¼˜å…ˆï¼šä¼˜å…ˆæŸ¥è¯¢ä¸åˆ†å‰²éŸ³èŠ‚æ•°ç›¸åŒçš„å®Œæ•´è¯ç»„
     * 2. ç©·å°½åŒé•¿åº¦è¯ç»„åï¼Œæ‰æŸ¥è¯¢è¾ƒçŸ­è¯ç»„
     * 3. æœ€åæä¾›å•å­—å€™é€‰è¯ä½œä¸ºå¤‡é€‰
     * 
     * ä¾‹å¦‚ï¼š["wei", "xin"] (2ä¸ªéŸ³èŠ‚)
     * - ç¬¬1å±‚ï¼šæŸ¥è¯¢2å­—è¯ç»„ (weixin) - å¾®ä¿¡ã€ç»´æ–°ã€å¨ä¿¡ç­‰
     * - ç¬¬2å±‚ï¼šå•å­—å€™é€‰ (weiå¼€å¤´çš„å­—ã€xinå¼€å¤´çš„å­—) - ä»…åœ¨2å­—è¯ç»„ä¸è¶³æ—¶
     */
    private suspend fun queryLayeredCandidates(segments: List<String>, limit: Int): List<WordFrequency> {
        val results = mutableListOf<WordFrequency>()
        val segmentCount = segments.size
        
        Timber.d("å¼€å§‹åˆ†å±‚æŸ¥è¯¢: ${segments.joinToString(" ")} (${segmentCount}ä¸ªéŸ³èŠ‚)")
        
        // ç¬¬1å±‚ï¼šä¼˜å…ˆæŸ¥è¯¢ä¸éŸ³èŠ‚æ•°ç›¸åŒçš„å®Œæ•´è¯ç»„
        if (segmentCount >= 2) {
            val fullPhrase = segments.joinToString("")
            val fullPhraseResults = queryPhraseByLength(fullPhrase, segmentCount, limit * 2) // å¢åŠ æŸ¥è¯¢æ•°é‡
            results.addAll(fullPhraseResults)
            Timber.d("ç¬¬1å±‚(${segmentCount}å­—è¯): $fullPhrase -> ${fullPhraseResults.size}ä¸ªç»“æœ")
            
            // å¦‚æœåŒé•¿åº¦è¯ç»„å·²ç»è¶³å¤Ÿï¼Œç›´æ¥è¿”å›
            if (results.size >= limit) {
                return results.take(limit)
            }
        }
        
        // ç¬¬2å±‚ï¼šåªæœ‰åœ¨åŒé•¿åº¦è¯ç»„ä¸è¶³æ—¶ï¼Œæ‰æŸ¥è¯¢è¾ƒçŸ­è¯ç»„
        if (results.size < limit && segmentCount > 2) {
            val remainingLimit = limit - results.size
            
            for (phraseLength in (segmentCount - 1) downTo 2) {
                if (results.size >= limit) break
                
                val layerResults = mutableListOf<WordFrequency>()
                val currentLayerLimit = remainingLimit / (segmentCount - 1)
                
                // ç”Ÿæˆè¯¥é•¿åº¦çš„æ‰€æœ‰å¯èƒ½ç»„åˆ
                for (startIndex in 0..(segmentCount - phraseLength)) {
                    val phraseSegments = segments.subList(startIndex, startIndex + phraseLength)
                    val phrase = phraseSegments.joinToString("")
                    
                    val phraseResults = queryPhraseByLength(phrase, phraseLength, currentLayerLimit)
                    layerResults.addAll(phraseResults)
                    
                    if (layerResults.size >= currentLayerLimit) break
                }
                
                results.addAll(layerResults.take(currentLayerLimit))
                Timber.d("ç¬¬${segmentCount - phraseLength + 1}å±‚(${phraseLength}å­—è¯): ${layerResults.size}ä¸ªç»“æœ")
            }
        }
        
        // æœ€åä¸€å±‚ï¼šå•å­—å€™é€‰è¯ï¼ˆä»…åœ¨è¯ç»„ä¸è¶³æ—¶æä¾›ï¼‰
        if (results.size < limit) {
            val remainingLimit = limit - results.size
            val singleCharResults = mutableListOf<WordFrequency>()
            
            for (segment in segments) {
                if (singleCharResults.size >= remainingLimit) break
                
                // æŸ¥è¯¢å•å­—Trie
                if (trieManager.isTrieLoaded(TrieType.CHARS)) {
                    val charResults = trieManager.searchByPrefix(TrieType.CHARS, segment, 5)
                    singleCharResults.addAll(charResults)
                }
                
                // æŸ¥è¯¢BASE Trieä¸­çš„å•å­—
                if (trieManager.isTrieLoaded(TrieType.BASE)) {
                    val baseResults = trieManager.searchByPrefix(TrieType.BASE, segment, 3)
                        .filter { it.word.length == 1 }
                    singleCharResults.addAll(baseResults)
                }
            }
            
            results.addAll(singleCharResults.distinctBy { it.word }.take(remainingLimit))
            Timber.d("æœ€åä¸€å±‚(å•å­—): ${singleCharResults.size}ä¸ªç»“æœ")
        }
        
        return results
    }
    
    /**
     * æŒ‰è¯é•¿æŸ¥è¯¢çŸ­è¯­
     */
    private suspend fun queryPhraseByLength(phrase: String, expectedLength: Int, limit: Int): List<WordFrequency> {
        val results = mutableListOf<WordFrequency>()
        
        if (trieManager.isTrieLoaded(TrieType.BASE)) {
            val baseResults = trieManager.searchByPrefix(TrieType.BASE, phrase, limit * 2)
                .filter { it.word.length == expectedLength }
            results.addAll(baseResults)
        }
        
        return results.take(limit)
    }
    
    /**
     * è®¡ç®—å„å±‚çš„å€™é€‰è¯æ•°é‡åˆ†é…
     */
    private fun calculateLayerLimits(segmentCount: Int, totalLimit: Int): List<Int> {
        val layers = segmentCount // æ€»å±‚æ•°
        val limits = mutableListOf<Int>()
        
        when {
            segmentCount <= 2 -> {
                // ç®€å•æƒ…å†µï¼šå¹³å‡åˆ†é…
                limits.add(totalLimit / 2)
                limits.add(totalLimit / 2)
            }
            segmentCount <= 4 -> {
                // ä¸­ç­‰å¤æ‚åº¦ï¼šå®Œæ•´è¯ç»„ä¼˜å…ˆ
                limits.add((totalLimit * 0.4).toInt()) // å®Œæ•´è¯ç»„
                limits.add((totalLimit * 0.3).toInt()) // æ¬¡é•¿è¯ç»„
                limits.add((totalLimit * 0.2).toInt()) // çŸ­è¯ç»„
                limits.add((totalLimit * 0.1).toInt()) // å•å­—
            }
            else -> {
                // é«˜å¤æ‚åº¦ï¼šæ›´å¤šå±‚çº§
                limits.add((totalLimit * 0.3).toInt()) // å®Œæ•´è¯ç»„
                limits.add((totalLimit * 0.25).toInt()) // æ¬¡é•¿è¯ç»„
                limits.add((totalLimit * 0.2).toInt()) // ä¸­ç­‰è¯ç»„
                limits.add((totalLimit * 0.15).toInt()) // çŸ­è¯ç»„
                limits.add((totalLimit * 0.1).toInt()) // å•å­—
            }
        }
        
        // ç¡®ä¿è‡³å°‘æ¯å±‚æœ‰1ä¸ªå€™é€‰
        return limits.map { maxOf(1, it) }
    }
    
    /**
     * æ•°æ®åº“ä¼˜å…ˆæŸ¥è¯¢
     */
    private suspend fun queryDatabasePriority(input: String, limit: Int): List<WordFrequency> {
        return withContext(Dispatchers.Default) {
            // æš‚æ—¶è¿”å›ç©ºåˆ—è¡¨ï¼Œåç»­å®ç°æ•°æ®åº“æŸ¥è¯¢
            emptyList()
        }
    }
    
    /**
     * æ¸è¿›å¼è¿‡æ»¤æŸ¥è¯¢
     */
    private suspend fun queryProgressiveFilter(input: String, limit: Int): List<WordFrequency> {
        return withContext(Dispatchers.Default) {
            // æŸ¥æ‰¾æœ€é•¿çš„å‰ç¼€ç¼“å­˜
            val prefixResult = findLongestPrefixCache(input)
            if (prefixResult != null) {
                // åŸºäºå‰ç¼€ç»“æœè¿‡æ»¤
                prefixResult.candidates.filter { candidate ->
                    matchesPinyinPattern(candidate.word, input)
                }.take(limit)
            } else {
                // å›é€€åˆ°æ··åˆæŸ¥è¯¢
                queryHybrid(input, limit)
            }
        }
    }
    
    /**
     * æ™ºèƒ½åˆ†å‰²æŸ¥è¯¢
     */
    private suspend fun queryWithSegmentation(input: String, limit: Int): List<WordFrequency> {
        return withContext(Dispatchers.Default) {
            val segmentations = generateSegmentations(input)
            val results = mutableListOf<WordFrequency>()
            
            for (segmentation in segmentations.take(3)) { // é™åˆ¶åˆ†å‰²æ•°é‡
                // æš‚æ—¶è·³è¿‡æ•°æ®åº“æŸ¥è¯¢ï¼Œä½¿ç”¨TrieæŸ¥è¯¢
                if (trieManager.isTrieLoaded(TrieType.BASE)) {
                    val segmentResults = trieManager.searchByPrefix(TrieType.BASE, segmentation, limit / 3)
                    results.addAll(segmentResults)
                    if (results.size >= limit) break
                }
            }
            
            results.distinctBy { it.word }.take(limit)
        }
    }
    
    /**
     * ç”Ÿæˆå¯èƒ½çš„åˆ†å‰²æ–¹æ¡ˆ - æ”¯æŒå£°æ¯æ­§ä¹‰æ€§å¤„ç†
     */
    private fun generateSegmentations(input: String): List<String> {
        val segmentations = mutableListOf<String>()
        
        // æ·»åŠ åŸå§‹è¾“å…¥
        segmentations.add(input)
        
        // å¤„ç†å¤è¾…éŸ³å£°æ¯çš„æ­§ä¹‰æ€§ï¼ˆzh, ch, shï¼‰
        val ambiguousSegmentations = handleInitialAmbiguity(input)
        segmentations.addAll(ambiguousSegmentations)
        
        // å¯¹äºé•¿è¾“å…¥ï¼Œè¿›è¡Œæ™ºèƒ½åˆ†å‰²
        if (input.length > 3) {
            val intelligentSegments = intelligentSegmentation(input)
            if (intelligentSegments.size > 1) {
                segmentations.add(intelligentSegments.joinToString(" "))
                
                // æ£€æŸ¥æ˜¯å¦ä¸ºå®Œç¾åˆ†å‰²
                val isValidSyllables = getValidSyllables()
                val isPerfectSegmentation = intelligentSegments.all { it in isValidSyllables }
                
                // åªæœ‰å½“æ™ºèƒ½åˆ†å‰²ä¸å®Œç¾æ—¶ï¼Œæ‰æ·»åŠ ç®€å•åˆ†å‰²ä½œä¸ºå¤‡é€‰
                if (!isPerfectSegmentation) {
                    for (i in 2..input.length-2 step 2) {
                        val part1 = input.substring(0, i)
                        val part2 = input.substring(i)
                        segmentations.add("$part1 $part2")
                    }
                }
            } else {
                // æ™ºèƒ½åˆ†å‰²å¤±è´¥ï¼Œä½¿ç”¨ç®€å•åˆ†å‰²
                for (i in 2..input.length-2 step 2) {
                    val part1 = input.substring(0, i)
                    val part2 = input.substring(i)
                    segmentations.add("$part1 $part2")
                }
            }
        }
        
        return segmentations.distinct()
    }
    
    /**
     * å¤„ç†å¤è¾…éŸ³å£°æ¯çš„æ­§ä¹‰æ€§
     * 
     * å¤è¾…éŸ³å£°æ¯ï¼šzh, ch, sh
     * è¿™äº›å¯èƒ½è¢«ç†è§£ä¸ºï¼š
     * 1. å®Œæ•´å£°æ¯ï¼ˆå¦‚ "sh" â†’ æŸ¥æ‰¾ä»¥shå¼€å¤´çš„éŸ³èŠ‚ï¼‰
     * 2. åˆ†ç¦»å­—æ¯ï¼ˆå¦‚ "sh" â†’ "s" + "h"ï¼‰
     */
    private fun handleInitialAmbiguity(input: String): List<String> {
        val ambiguousSegmentations = mutableListOf<String>()
        
        // å¤è¾…éŸ³å£°æ¯åˆ—è¡¨
        val compoundInitials = setOf("zh", "ch", "sh")
        
        when (input.length) {
            2 -> {
                // å¯¹äº2å­—ç¬¦è¾“å…¥ï¼Œæ£€æŸ¥æ˜¯å¦ä¸ºå¤è¾…éŸ³å£°æ¯
                if (input in compoundInitials) {
                    // æ–¹æ¡ˆ1ï¼šä½œä¸ºå®Œæ•´å£°æ¯
                    // å·²ç»åœ¨åŸå§‹è¾“å…¥ä¸­åŒ…å«
                    
                    // æ–¹æ¡ˆ2ï¼šä½œä¸ºåˆ†ç¦»å­—æ¯
                    ambiguousSegmentations.add("${input[0]} ${input[1]}")
                }
            }
            3 -> {
                // å¯¹äº3å­—ç¬¦è¾“å…¥ï¼Œæ£€æŸ¥å‰2ä¸ªå­—ç¬¦æ˜¯å¦ä¸ºå¤è¾…éŸ³å£°æ¯
                val firstTwo = input.substring(0, 2)
                if (firstTwo in compoundInitials) {
                    // æ–¹æ¡ˆ1ï¼šå¤è¾…éŸ³å£°æ¯ + å•å­—ç¬¦
                    ambiguousSegmentations.add("$firstTwo ${input[2]}")
                    
                    // æ–¹æ¡ˆ2ï¼šå•å­—ç¬¦ + å•å­—ç¬¦ + å•å­—ç¬¦
                    ambiguousSegmentations.add("${input[0]} ${input[1]} ${input[2]}")
                }
                
                // æ£€æŸ¥å2ä¸ªå­—ç¬¦æ˜¯å¦ä¸ºå¤è¾…éŸ³å£°æ¯
                val lastTwo = input.substring(1, 3)
                if (lastTwo in compoundInitials) {
                    // æ–¹æ¡ˆ3ï¼šå•å­—ç¬¦ + å¤è¾…éŸ³å£°æ¯
                    ambiguousSegmentations.add("${input[0]} $lastTwo")
                }
            }
            4 -> {
                // å¯¹äº4å­—ç¬¦è¾“å…¥ï¼Œæ£€æŸ¥å„ç§å¤è¾…éŸ³å£°æ¯ç»„åˆ
                val firstTwo = input.substring(0, 2)
                val lastTwo = input.substring(2, 4)
                
                if (firstTwo in compoundInitials && lastTwo in compoundInitials) {
                    // æ–¹æ¡ˆ1ï¼šå¤è¾…éŸ³å£°æ¯ + å¤è¾…éŸ³å£°æ¯
                    ambiguousSegmentations.add("$firstTwo $lastTwo")
                }
                
                if (firstTwo in compoundInitials) {
                    // æ–¹æ¡ˆ2ï¼šå¤è¾…éŸ³å£°æ¯ + å•å­—ç¬¦ + å•å­—ç¬¦
                    ambiguousSegmentations.add("$firstTwo ${input[2]} ${input[3]}")
                }
                
                if (lastTwo in compoundInitials) {
                    // æ–¹æ¡ˆ3ï¼šå•å­—ç¬¦ + å•å­—ç¬¦ + å¤è¾…éŸ³å£°æ¯
                    ambiguousSegmentations.add("${input[0]} ${input[1]} $lastTwo")
                }
            }
        }
        
        return ambiguousSegmentations
    }
    
    /**
     * è·å–æœ‰æ•ˆéŸ³èŠ‚é›†åˆ
     */
    private fun getValidSyllables(): Set<String> {
        return setOf(
            "a", "e", "o", "ai", "ei", "ao", "ou", "an", "en", "ang", "eng", "er",
            "ba", "bai", "ban", "bang", "bao", "bei", "ben", "beng", "bi", "bian", "biao", "bie", "bin", "bing", "bo", "bu",
            "ca", "cai", "can", "cang", "cao", "ce", "cen", "ceng", "ci", "cong", "cou", "cu", "cuan", "cui", "cun", "cuo",
            "da", "dai", "dan", "dang", "dao", "de", "dei", "den", "deng", "di", "dian", "diao", "die", "ding", "diu", "dong", "dou", "du", "duan", "dui", "dun", "duo",
            "fa", "fan", "fang", "fei", "fen", "feng", "fo", "fou", "fu",
            "ga", "gai", "gan", "gang", "gao", "ge", "gei", "gen", "geng", "gong", "gou", "gu", "gua", "guai", "guan", "guang", "gui", "gun", "guo",
            "ha", "hai", "han", "hang", "hao", "he", "hei", "hen", "heng", "hong", "hou", "hu", "hua", "huai", "huan", "huang", "hui", "hun", "huo",
            "ji", "jia", "jian", "jiang", "jiao", "jie", "jin", "jing", "jiong", "jiu", "ju", "juan", "jue", "jun",
            "ka", "kai", "kan", "kang", "kao", "ke", "ken", "keng", "kong", "kou", "ku", "kua", "kuai", "kuan", "kuang", "kui", "kun", "kuo",
            "la", "lai", "lan", "lang", "lao", "le", "lei", "leng", "li", "lia", "lian", "liang", "liao", "lie", "lin", "ling", "liu", "long", "lou", "lu", "luan", "lue", "lun", "luo", "lv",
            "ma", "mai", "man", "mang", "mao", "me", "mei", "men", "meng", "mi", "mian", "miao", "mie", "min", "ming", "miu", "mo", "mou", "mu",
            "na", "nai", "nan", "nang", "nao", "ne", "nei", "nen", "neng", "ni", "nian", "niang", "niao", "nie", "nin", "ning", "niu", "nong", "nou", "nu", "nuan", "nue", "nuo", "nv",
            "pa", "pai", "pan", "pang", "pao", "pei", "pen", "peng", "pi", "pian", "piao", "pie", "pin", "ping", "po", "pou", "pu",
            "qi", "qia", "qian", "qiang", "qiao", "qie", "qin", "qing", "qiong", "qiu", "qu", "quan", "que", "qun",
            "ran", "rang", "rao", "re", "ren", "reng", "ri", "rong", "rou", "ru", "ruan", "rui", "run", "ruo",
            "sa", "sai", "san", "sang", "sao", "se", "sen", "seng", "si", "song", "sou", "su", "suan", "sui", "sun", "suo",
            "ta", "tai", "tan", "tang", "tao", "te", "teng", "ti", "tian", "tiao", "tie", "ting", "tong", "tou", "tu", "tuan", "tui", "tun", "tuo",
            "wa", "wai", "wan", "wang", "wei", "wen", "weng", "wo", "wu",
            "xi", "xia", "xian", "xiang", "xiao", "xie", "xin", "xing", "xiong", "xiu", "xu", "xuan", "xue", "xun",
            "ya", "yan", "yang", "yao", "ye", "yi", "yin", "ying", "yo", "yong", "you", "yu", "yuan", "yue", "yun",
            "za", "zai", "zan", "zang", "zao", "ze", "zei", "zen", "zeng", "zi", "zong", "zou", "zu", "zuan", "zui", "zun", "zuo",
            "zha", "zhai", "zhan", "zhang", "zhao", "zhe", "zhei", "zhen", "zheng", "zhi", "zhong", "zhou", "zhu", "zhua", "zhuai", "zhuan", "zhuang", "zhui", "zhun", "zhuo",
            "cha", "chai", "chan", "chang", "chao", "che", "chen", "cheng", "chi", "chong", "chou", "chu", "chua", "chuai", "chuan", "chuang", "chui", "chun", "chuo",
            "sha", "shai", "shan", "shang", "shao", "she", "shei", "shen", "sheng", "shi", "shou", "shu", "shua", "shuai", "shuan", "shuang", "shui", "shun", "shuo"
        )
    }
    
    /**
     * æ™ºèƒ½åˆ†å‰²è¾“å…¥ä¸ºæœ‰æ•ˆçš„æ‹¼éŸ³éŸ³èŠ‚
     */
    private fun intelligentSegmentation(input: String): List<String> {
        val segments = mutableListOf<String>()
        var i = 0
        
        // å¸¸è§æ‹¼éŸ³éŸ³èŠ‚æ¨¡å¼ï¼ˆå®Œæ•´éŸ³èŠ‚ï¼Œä¸åŒ…æ‹¬å•ç‹¬çš„å£°æ¯ï¼‰
        val validSyllables = setOf(
            // å•éŸµæ¯ï¼ˆå¯ä»¥ç‹¬ç«‹æˆå­—ï¼‰
            "a", "e", "o", "ai", "ei", "ao", "ou", "an", "en", "ang", "eng", "er",
            // bç³»åˆ—
            "ba", "bai", "ban", "bang", "bao", "bei", "ben", "beng", "bi", "bian", "biao", "bie", "bin", "bing", "bo", "bu",
            // cç³»åˆ—  
            "ca", "cai", "can", "cang", "cao", "ce", "cen", "ceng", "ci", "cong", "cou", "cu", "cuan", "cui", "cun", "cuo",
            // dç³»åˆ—
            "da", "dai", "dan", "dang", "dao", "de", "dei", "den", "deng", "di", "dian", "diao", "die", "ding", "diu", "dong", "dou", "du", "duan", "dui", "dun", "duo",
            // fç³»åˆ—
            "fa", "fan", "fang", "fei", "fen", "feng", "fo", "fou", "fu",
            // gç³»åˆ—
            "ga", "gai", "gan", "gang", "gao", "ge", "gei", "gen", "geng", "gong", "gou", "gu", "gua", "guai", "guan", "guang", "gui", "gun", "guo",
            // hç³»åˆ—
            "ha", "hai", "han", "hang", "hao", "he", "hei", "hen", "heng", "hong", "hou", "hu", "hua", "huai", "huan", "huang", "hui", "hun", "huo",
            // jç³»åˆ—
            "ji", "jia", "jian", "jiang", "jiao", "jie", "jin", "jing", "jiong", "jiu", "ju", "juan", "jue", "jun",
            // kç³»åˆ—
            "ka", "kai", "kan", "kang", "kao", "ke", "ken", "keng", "kong", "kou", "ku", "kua", "kuai", "kuan", "kuang", "kui", "kun", "kuo",
            // lç³»åˆ—
            "la", "lai", "lan", "lang", "lao", "le", "lei", "leng", "li", "lia", "lian", "liang", "liao", "lie", "lin", "ling", "liu", "long", "lou", "lu", "luan", "lue", "lun", "luo", "lv",
            // mç³»åˆ—
            "ma", "mai", "man", "mang", "mao", "me", "mei", "men", "meng", "mi", "mian", "miao", "mie", "min", "ming", "miu", "mo", "mou", "mu",
            // nç³»åˆ—
            "na", "nai", "nan", "nang", "nao", "ne", "nei", "nen", "neng", "ni", "nian", "niang", "niao", "nie", "nin", "ning", "niu", "nong", "nou", "nu", "nuan", "nue", "nuo", "nv",
            // pç³»åˆ—
            "pa", "pai", "pan", "pang", "pao", "pei", "pen", "peng", "pi", "pian", "piao", "pie", "pin", "ping", "po", "pou", "pu",
            // qç³»åˆ—
            "qi", "qia", "qian", "qiang", "qiao", "qie", "qin", "qing", "qiong", "qiu", "qu", "quan", "que", "qun",
            // rç³»åˆ—
            "ran", "rang", "rao", "re", "ren", "reng", "ri", "rong", "rou", "ru", "ruan", "rui", "run", "ruo",
            // sç³»åˆ—
            "sa", "sai", "san", "sang", "sao", "se", "sen", "seng", "si", "song", "sou", "su", "suan", "sui", "sun", "suo",
            // tç³»åˆ—
            "ta", "tai", "tan", "tang", "tao", "te", "teng", "ti", "tian", "tiao", "tie", "ting", "tong", "tou", "tu", "tuan", "tui", "tun", "tuo",
            // wç³»åˆ—
            "wa", "wai", "wan", "wang", "wei", "wen", "weng", "wo", "wu",
            // xç³»åˆ—
            "xi", "xia", "xian", "xiang", "xiao", "xie", "xin", "xing", "xiong", "xiu", "xu", "xuan", "xue", "xun",
            // yç³»åˆ—
            "ya", "yan", "yang", "yao", "ye", "yi", "yin", "ying", "yo", "yong", "you", "yu", "yuan", "yue", "yun",
            // zç³»åˆ—
            "za", "zai", "zan", "zang", "zao", "ze", "zei", "zen", "zeng", "zi", "zong", "zou", "zu", "zuan", "zui", "zun", "zuo",
            // zhç³»åˆ—
            "zha", "zhai", "zhan", "zhang", "zhao", "zhe", "zhei", "zhen", "zheng", "zhi", "zhong", "zhou", "zhu", "zhua", "zhuai", "zhuan", "zhuang", "zhui", "zhun", "zhuo",
            // chç³»åˆ—
            "cha", "chai", "chan", "chang", "chao", "che", "chen", "cheng", "chi", "chong", "chou", "chu", "chua", "chuai", "chuan", "chuang", "chui", "chun", "chuo",
            // shç³»åˆ—
            "sha", "shai", "shan", "shang", "shao", "she", "shei", "shen", "sheng", "shi", "shou", "shu", "shua", "shuai", "shuan", "shuang", "shui", "shun", "shuo"
        )
        
        // ç‰¹æ®Šå¤„ç†çš„å•å­—æ¯ï¼ˆå¯ä»¥ä½œä¸ºç¼©å†™ï¼‰
        val validSingleChars = setOf("b", "c", "d", "f", "g", "h", "j", "k", "l", "m", "n", "p", "q", "r", "s", "t", "w", "x", "y", "z")
        
        while (i < input.length) {
            var found = false
            
            // å°è¯•åŒ¹é…æœ€é•¿çš„æœ‰æ•ˆéŸ³èŠ‚ï¼ˆä»é•¿åˆ°çŸ­ï¼Œä½†ä¼˜å…ˆå®Œæ•´éŸ³èŠ‚ï¼‰
            for (len in minOf(6, input.length - i) downTo 2) {
                val candidate = input.substring(i, i + len)
                if (validSyllables.contains(candidate)) {
                    segments.add(candidate)
                    i += len
                    found = true
                    break
                }
            }
            
            // å¦‚æœæ²¡æœ‰æ‰¾åˆ°é•¿éŸ³èŠ‚ï¼Œæ£€æŸ¥å•å­—ç¬¦
            if (!found) {
                val singleChar = input.substring(i, i + 1)
                if (validSyllables.contains(singleChar) || validSingleChars.contains(singleChar)) {
                    segments.add(singleChar)
                    i++
                    found = true
                }
            }
            
            // å¦‚æœè¿˜æ˜¯æ²¡æ‰¾åˆ°ï¼Œæ·»åŠ å•ä¸ªå­—ç¬¦ï¼ˆä½œä¸ºæ— æ•ˆè¾“å…¥ï¼‰
            if (!found) {
                segments.add(input.substring(i, i + 1))
                i++
            }
        }
        
        return segments
    }
    
    /**
     * æ£€æŸ¥æ¸è¿›å¼ç¼“å­˜
     */
    private fun checkProgressiveCache(input: String): CachedResult? {
        return progressiveCache.get(input)
    }
    
    /**
     * æ£€æŸ¥æ˜¯å¦æœ‰æ¸è¿›å¼å‰ç¼€
     */
    private fun hasProgressivePrefix(input: String): Boolean {
        for (i in input.length - 1 downTo 1) {
            val prefix = input.substring(0, i)
            if (progressiveCache.get(prefix) != null) {
                return true
            }
        }
        return false
    }
    
    /**
     * æŸ¥æ‰¾æœ€é•¿çš„å‰ç¼€ç¼“å­˜
     */
    private fun findLongestPrefixCache(input: String): CachedResult? {
        for (i in input.length - 1 downTo 1) {
            val prefix = input.substring(0, i)
            val cached = progressiveCache.get(prefix)
            if (cached != null) {
                return cached
            }
        }
        return null
    }
    
    /**
     * ç¼©å†™åŒ¹é…æŸ¥è¯¢
     */
    private suspend fun queryAbbreviationMatch(input: String, limit: Int): List<WordFrequency> {
        return withContext(Dispatchers.Default) {
            val results = mutableListOf<WordFrequency>()
            
            // 1. é¦–å…ˆæŸ¥è¯¢å•å­—æ¯å¼€å¤´çš„è¯è¯­ï¼ˆå¦‚"w"å¼€å¤´çš„è¯ï¼‰
            val firstChar = input.first().toString()
            if (trieManager.isTrieLoaded(TrieType.BASE)) {
                val firstCharResults = trieManager.searchByPrefix(TrieType.BASE, firstChar, limit * 2)
                results.addAll(firstCharResults)
            }
            
            // 2. æŸ¥è¯¢å•å­—Trieä¸­é¦–å­—æ¯åŒ¹é…çš„å­—
            if (trieManager.isTrieLoaded(TrieType.CHARS)) {
                val charResults = trieManager.searchByPrefix(TrieType.CHARS, firstChar, limit)
                results.addAll(charResults)
            }
            
            // 3. å°è¯•æŸ¥è¯¢å®Œæ•´ç¼©å†™åŒ¹é…ï¼ˆå¦‚æœè¾“å…¥é•¿åº¦>1ï¼‰
            if (input.length > 1) {
                // å°è¯•ç›´æ¥æŸ¥è¯¢ç¼©å†™æ¨¡å¼
                if (trieManager.isTrieLoaded(TrieType.BASE)) {
                    val abbreviationResults = trieManager.searchByPrefix(TrieType.BASE, input, limit)
                    results.addAll(abbreviationResults)
                }
            }
            
            // æŒ‰é¢‘ç‡æ’åºå¹¶å»é‡
            results.distinctBy { it.word }
                .sortedByDescending { it.frequency }
                .take(limit)
        }
    }
    
    /**
     * åˆ¤æ–­æ˜¯å¦ä¸ºç¼©å†™æ¨¡å¼
     */
    private fun isAbbreviationPattern(input: String): Boolean {
        // 2-4ä¸ªå­—ç¬¦ï¼Œå…¨éƒ¨æ˜¯è¾…éŸ³å­—æ¯
        val consonants = "bcdfghjklmnpqrstvwxyz"
        return input.length in 2..4 && input.all { it in consonants }
    }
    

    
    /**
     * æ‹¼éŸ³æ¨¡å¼åŒ¹é…
     */
    private fun matchesPinyinPattern(word: String, pinyin: String): Boolean {
        // ç®€åŒ–çš„æ‹¼éŸ³åŒ¹é…é€»è¾‘
        // è¿™é‡Œåº”è¯¥å®ç°æ›´å¤æ‚çš„æ‹¼éŸ³åŒ¹é…ç®—æ³•
        return true // ä¸´æ—¶è¿”å›trueï¼Œåç»­å®Œå–„
    }
    
    /**
     * è·å–TrieçŠ¶æ€
     */
    private fun getTrieStatus(): String {
        return buildString {
            append("CHARS: ${if (trieManager.isTrieLoaded(TrieType.CHARS)) "å·²åŠ è½½" else "æœªåŠ è½½"}")
            append(", BASE: ${if (trieManager.isTrieLoaded(TrieType.BASE)) "å·²åŠ è½½" else "æœªåŠ è½½"}")
        }
    }
    
    /**
     * æ¸…ç†ç¼“å­˜
     */
    fun clearCache() {
        progressiveCache.evictAll()
        Timber.d("SmartPinyinEngine: ç¼“å­˜å·²æ¸…ç†")
    }
    
    /**
     * è·å–æ€§èƒ½ç»Ÿè®¡
     */
    fun getPerformanceStats(): String {
        val avgTime = if (queryCount.get() > 0) {
            totalQueryTime.get() / queryCount.get()
        } else 0
        
        val hitRate = if (queryCount.get() > 0) {
            (cacheHits.get() * 100.0 / queryCount.get()).toInt()
        } else 0
        
        return buildString {
            appendLine("ğŸ“Š SmartPinyinEngine æ€§èƒ½ç»Ÿè®¡:")
            appendLine("æŸ¥è¯¢æ€»æ•°: ${queryCount.get()}")
            appendLine("ç¼“å­˜å‘½ä¸­: ${cacheHits.get()} (${hitRate}%)")
            appendLine("å¹³å‡è€—æ—¶: ${avgTime}ms")
            appendLine("ç¼“å­˜å¤§å°: ${progressiveCache.size()}/200")
        }
    }
} 