#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import struct
import os
from typing import List, Tuple, Dict

def remove_tone_marks(pinyin: str) -> str:
    """å»é™¤æ‹¼éŸ³ä¸­çš„å£°è°ƒç¬¦å·"""
    tone_map = {
        'Ä': 'a', 'Ã¡': 'a', 'Ç': 'a', 'Ã ': 'a',
        'Ä“': 'e', 'Ã©': 'e', 'Ä›': 'e', 'Ã¨': 'e',
        'Ä«': 'i', 'Ã­': 'i', 'Ç': 'i', 'Ã¬': 'i',
        'Å': 'o', 'Ã³': 'o', 'Ç’': 'o', 'Ã²': 'o',
        'Å«': 'u', 'Ãº': 'u', 'Ç”': 'u', 'Ã¹': 'u',
        'Ç–': 'Ã¼', 'Ç˜': 'Ã¼', 'Çš': 'Ã¼', 'Çœ': 'Ã¼', 'Ã¼': 'v',
        'Å„': 'n', 'Åˆ': 'n', 'Ç¹': 'n'
    }
    
    result = ""
    for char in pinyin:
        result += tone_map.get(char, char)
    
    return result

def parse_chars_dict_file(file_path: str) -> List[Tuple[str, str, int]]:
    """è§£æcharsè¯å…¸æ–‡ä»¶ï¼Œè¿”å›(è¯è¯­, æ‹¼éŸ³, è¯é¢‘)çš„åˆ—è¡¨"""
    entries = []
    filtered_count = 0
    
    print(f"æ­£åœ¨è§£æcharsè¯å…¸æ–‡ä»¶: {file_path}")
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            line_count = 0
            for line in f:
                line_count += 1
                if line_count % 50000 == 0:
                    print(f"å·²å¤„ç† {line_count} è¡Œ...")
                
                line = line.strip()
                if not line:
                    continue
                
                parts = line.split('\t')
                if len(parts) >= 3:
                    word = parts[0].strip()
                    pinyin = parts[1].strip()
                    
                    # è¿‡æ»¤æ‰æ‹¼éŸ³ä¸º"æ— "çš„è¯æ¡
                    if pinyin == "æ— ":
                        filtered_count += 1
                        continue
                    
                    # è¿‡æ»¤æ‰ç©ºæ‹¼éŸ³æˆ–æ— æ•ˆæ‹¼éŸ³
                    if not pinyin or len(pinyin.strip()) == 0:
                        filtered_count += 1
                        continue
                    
                    try:
                        frequency = int(parts[2].strip())
                        pinyin_no_tone = remove_tone_marks(pinyin)
                        entries.append((word, pinyin_no_tone, frequency))
                    except ValueError:
                        filtered_count += 1
                        continue
    
    except Exception as e:
        print(f"é”™è¯¯ï¼šè§£ææ–‡ä»¶å¤±è´¥ - {e}")
        return []
    
    print(f"è§£æå®Œæˆï¼Œå…±è·å¾— {len(entries)} ä¸ªæœ‰æ•ˆè¯æ¡")
    print(f"è¿‡æ»¤æ‰ {filtered_count} ä¸ªæ— æ•ˆè¯æ¡ï¼ˆæ‹¼éŸ³ä¸º'æ— 'æˆ–ç©ºï¼‰")
    return entries

def build_unlimited_trie_data(entries: List[Tuple[str, str, int]]) -> Dict:
    """æ„å»ºæ— é™åˆ¶çš„Trieæ•°æ®ç»“æ„ï¼ˆä¸é™åˆ¶æ¯ä¸ªæ‹¼éŸ³çš„è¯æ•°ï¼‰"""
    print("æ­£åœ¨æ„å»ºæ— é™åˆ¶Trieæ•°æ®...")
    
    trie_data = {}
    
    for i, (word, pinyin, frequency) in enumerate(entries):
        if i % 10000 == 0:
            print(f"å·²å¤„ç† {i} ä¸ªè¯æ¡...")
        
        # æ¸…ç†æ‹¼éŸ³æ ¼å¼
        pinyin_clean = ' '.join(pinyin.lower().split())
        
        # å­˜å‚¨åˆ°å­—å…¸ä¸­
        if pinyin_clean not in trie_data:
            trie_data[pinyin_clean] = []
        
        trie_data[pinyin_clean].append({
            'word': word,
            'frequency': frequency
        })
    
    # å¯¹æ¯ä¸ªæ‹¼éŸ³çš„è¯è¯­æŒ‰é¢‘ç‡æ’åºï¼ˆä¸é™åˆ¶æ•°é‡ï¼‰
    total_words = 0
    for pinyin in trie_data:
        trie_data[pinyin].sort(key=lambda x: x['frequency'], reverse=True)
        total_words += len(trie_data[pinyin])
    
    print(f"æ— é™åˆ¶Trieæ„å»ºå®Œæˆï¼åŒ…å« {len(trie_data)} ä¸ªæ‹¼éŸ³æ¡ç›®ï¼Œæ€»è¯æ•°: {total_words}")
    return trie_data

def save_trie_data_file(trie_data: Dict, output_path: str) -> bool:
    """ä¿å­˜Trieæ•°æ®æ–‡ä»¶"""
    print(f"æ­£åœ¨ä¿å­˜Trieæ•°æ®åˆ°æ–‡ä»¶: {output_path}")
    
    try:
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        
        with open(output_path, 'wb') as f:
            # å†™å…¥ç‰ˆæœ¬å·
            f.write(struct.pack('>i', 3))  # ä½¿ç”¨ç‰ˆæœ¬3è¡¨ç¤ºç®€åŒ–æ ¼å¼
            
            # å†™å…¥æ•°æ®æ¡ç›®æ•°é‡
            f.write(struct.pack('>i', len(trie_data)))
            
            # å†™å…¥æ¯ä¸ªæ¡ç›®
            for pinyin, words in trie_data.items():
                # å†™å…¥æ‹¼éŸ³é•¿åº¦å’Œæ‹¼éŸ³
                pinyin_bytes = pinyin.encode('utf-8')
                f.write(struct.pack('>i', len(pinyin_bytes)))
                f.write(pinyin_bytes)
                
                # å†™å…¥è¯è¯­æ•°é‡
                f.write(struct.pack('>i', len(words)))
                
                # å†™å…¥æ¯ä¸ªè¯è¯­
                for word_item in words:
                    word_bytes = word_item['word'].encode('utf-8')
                    f.write(struct.pack('>i', len(word_bytes)))
                    f.write(word_bytes)
                    f.write(struct.pack('>i', word_item['frequency']))
        
        file_size = os.path.getsize(output_path)
        print(f"æ–‡ä»¶ä¿å­˜æˆåŠŸï¼æ–‡ä»¶å¤§å°: {file_size} å­—èŠ‚ ({file_size/1024/1024:.2f} MB)")
        
        return True
        
    except Exception as e:
        print(f"é”™è¯¯ï¼šä¿å­˜æ–‡ä»¶å¤±è´¥ - {e}")
        return False

def verify_trie_data_file(file_path: str) -> bool:
    """éªŒè¯ç”Ÿæˆçš„Trieæ•°æ®æ–‡ä»¶"""
    print(f"æ­£åœ¨éªŒè¯æ•°æ®æ–‡ä»¶: {file_path}")
    
    try:
        with open(file_path, 'rb') as f:
            # è¯»å–ç‰ˆæœ¬å·
            version_bytes = f.read(4)
            if len(version_bytes) != 4:
                print("é”™è¯¯ï¼šæ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®")
                return False
            
            version = struct.unpack('>i', version_bytes)[0]
            print(f"æ–‡ä»¶ç‰ˆæœ¬å·: {version}")
            
            # è¯»å–æ•°æ®æ¡ç›®æ•°é‡
            count_bytes = f.read(4)
            count = struct.unpack('>i', count_bytes)[0]
            print(f"æ‹¼éŸ³æ¡ç›®æ•°é‡: {count}")
            
            # éªŒè¯å‰å‡ ä¸ªæ¡ç›®
            total_words = 0
            for i in range(min(5, count)):
                # è¯»å–æ‹¼éŸ³
                pinyin_len = struct.unpack('>i', f.read(4))[0]
                pinyin = f.read(pinyin_len).decode('utf-8')
                
                # è¯»å–è¯è¯­æ•°é‡
                word_count = struct.unpack('>i', f.read(4))[0]
                total_words += word_count
                
                words = []
                for j in range(min(3, word_count)):  # åªæ˜¾ç¤ºå‰3ä¸ªè¯
                    word_len = struct.unpack('>i', f.read(4))[0]
                    word = f.read(word_len).decode('utf-8')
                    frequency = struct.unpack('>i', f.read(4))[0]
                    words.append(f"{word}({frequency})")
                
                # è·³è¿‡å‰©ä½™çš„è¯è¯­
                for j in range(3, word_count):
                    word_len = struct.unpack('>i', f.read(4))[0]
                    f.seek(f.tell() + word_len + 4)  # è·³è¿‡è¯è¯­å†…å®¹å’Œé¢‘ç‡
                
                print(f"   '{pinyin}' -> {', '.join(words)} (å…±{word_count}ä¸ªè¯)")
            
            # è®¡ç®—æ€»è¯æ•°ï¼ˆä¼°ç®—ï¼‰
            f.seek(8)  # å›åˆ°æ•°æ®å¼€å§‹ä½ç½®
            actual_total_words = 0
            for i in range(count):
                # è·³è¿‡æ‹¼éŸ³
                pinyin_len = struct.unpack('>i', f.read(4))[0]
                f.seek(f.tell() + pinyin_len)
                
                # è¯»å–è¯è¯­æ•°é‡
                word_count = struct.unpack('>i', f.read(4))[0]
                actual_total_words += word_count
                
                # è·³è¿‡æ‰€æœ‰è¯è¯­
                for j in range(word_count):
                    word_len = struct.unpack('>i', f.read(4))[0]
                    f.seek(f.tell() + word_len + 4)  # è·³è¿‡è¯è¯­å†…å®¹å’Œé¢‘ç‡
            
            print(f"éªŒè¯æˆåŠŸï¼å®é™…æ€»è¯è¯­æ•°: {actual_total_words}")
            return True
            
    except Exception as e:
        print(f"é”™è¯¯ï¼šéªŒè¯æ–‡ä»¶å¤±è´¥ - {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    input_path = "app/src/main/assets/cn_dicts/chars.dict.yaml"
    output_path = "app/src/main/assets/trie/chars_trie.dat"
    
    print("=" * 60)
    print("ç¥æœºè¾“å…¥æ³• - æ— é™åˆ¶chars Trieæ„å»ºå·¥å…·")
    print("=" * 60)
    print(f"è¾“å…¥æ–‡ä»¶: {input_path}")
    print(f"è¾“å‡ºæ–‡ä»¶: {output_path}")
    print("=" * 60)
    
    # è§£æè¯å…¸æ–‡ä»¶
    entries = parse_chars_dict_file(input_path)
    if not entries:
        print("âŒ è§£æè¯å…¸æ–‡ä»¶å¤±è´¥")
        return 1
    
    # æ„å»ºTrieæ•°æ®
    trie_data = build_unlimited_trie_data(entries)
    if not trie_data:
        print("âŒ æ„å»ºTrieæ•°æ®å¤±è´¥")
        return 1
    
    # ä¿å­˜æ–‡ä»¶
    if not save_trie_data_file(trie_data, output_path):
        print("âŒ ä¿å­˜æ–‡ä»¶å¤±è´¥")
        return 1
    
    # éªŒè¯æ–‡ä»¶
    if not verify_trie_data_file(output_path):
        print("âŒ éªŒè¯æ–‡ä»¶å¤±è´¥")
        return 1
    
    print("=" * 60)
    print("âœ… æ— é™åˆ¶chars Trieæ–‡ä»¶æ„å»ºæˆåŠŸï¼")
    print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {output_path}")
    print("=" * 60)
    
    return 0

if __name__ == "__main__":
    exit(main()) 