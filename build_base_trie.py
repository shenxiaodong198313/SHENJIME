#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç¥è¿¹è¾“å…¥æ³• - Baseè¯å…¸Trieé¢„ç¼–è¯‘æ„å»ºå·¥å…·
åŠŸèƒ½ï¼š
1. è§£æbase.dict.yamlæ–‡ä»¶
2. å»æ‰æ‹¼éŸ³å£°è°ƒ
3. é€‰æ‹©è¯é¢‘æœ€é«˜50%çš„è¯è¯­
4. æ„å»ºTrieæ•°æ®ç»“æ„
5. ç”Ÿæˆé¢„ç¼–è¯‘æ–‡ä»¶
"""

import os
import sys
import re
import pickle
import struct
from typing import Dict, List, Tuple, Optional
from collections import defaultdict
import unicodedata

class WordItem:
    """è¯è¯­é¡¹ï¼Œå¯¹åº”Javaä¸­çš„WordItemç±»"""
    def __init__(self, word: str, frequency: int):
        self.word = word
        self.frequency = frequency
    
    def __repr__(self):
        return f"WordItem(word='{self.word}', frequency={self.frequency})"

class TrieNode:
    """Trieæ ‘èŠ‚ç‚¹ï¼Œå¯¹åº”Javaä¸­çš„TrieNodeç±»"""
    MAX_WORDS_PER_NODE = 50
    
    def __init__(self):
        self.children: Dict[str, 'TrieNode'] = {}
        self.words: List[WordItem] = []
        self.is_end_of_word = False
    
    def add_word(self, word: str, frequency: int) -> bool:
        """æ·»åŠ è¯è¯­åˆ°èŠ‚ç‚¹"""
        # å¦‚æœåˆ—è¡¨æœªæ»¡ï¼Œç›´æ¥æ·»åŠ 
        if len(self.words) < self.MAX_WORDS_PER_NODE:
            self.words.append(WordItem(word, frequency))
            self.words.sort(key=lambda x: x.frequency, reverse=True)
            return True
        
        # å¦‚æœåˆ—è¡¨å·²æ»¡ï¼Œæ£€æŸ¥æ˜¯å¦å¯ä»¥æ›¿æ¢æœ€ä½é¢‘ç‡çš„è¯
        lowest_freq_item = min(self.words, key=lambda x: x.frequency)
        if frequency > lowest_freq_item.frequency:
            self.words.remove(lowest_freq_item)
            self.words.append(WordItem(word, frequency))
            self.words.sort(key=lambda x: x.frequency, reverse=True)
            return True
        
        return False
    
    def calculate_memory_stats(self) -> Tuple[int, int]:
        """è®¡ç®—å†…å­˜ç»Ÿè®¡ä¿¡æ¯ï¼š(èŠ‚ç‚¹æ•°, è¯è¯­æ•°)"""
        node_count = 1
        word_count = len(self.words)
        
        for child in self.children.values():
            child_nodes, child_words = child.calculate_memory_stats()
            node_count += child_nodes
            word_count += child_words
        
        return node_count, word_count

class PinyinTrie:
    """æ‹¼éŸ³Trieæ ‘ï¼Œå¯¹åº”Javaä¸­çš„PinyinTrieç±»"""
    def __init__(self):
        self.root = TrieNode()
        self.syllable_separator = "'"
    
    def insert(self, pinyin: str, word: str, frequency: int):
        """æ’å…¥æ‹¼éŸ³å’Œå¯¹åº”çš„æ±‰å­—"""
        current = self.root
        
        # éå†æ‹¼éŸ³çš„æ¯ä¸ªå­—ç¬¦
        for char in pinyin:
            if char not in current.children:
                current.children[char] = TrieNode()
            current = current.children[char]
        
        # æ ‡è®°ä¸ºè¯è¯­ç»“å°¾
        current.is_end_of_word = True
        
        # æ·»åŠ è¯è¯­åˆ°å½“å‰èŠ‚ç‚¹
        current.add_word(word, frequency)
    
    def get_memory_stats(self) -> Tuple[int, int]:
        """è·å–å†…å­˜ç»Ÿè®¡ä¿¡æ¯"""
        return self.root.calculate_memory_stats()
    
    def is_empty(self) -> bool:
        """åˆ¤æ–­Trieæ ‘æ˜¯å¦ä¸ºç©º"""
        return len(self.root.children) == 0

def remove_tone_marks(pinyin: str) -> str:
    """å»é™¤æ‹¼éŸ³ä¸­çš„å£°è°ƒç¬¦å·"""
    # å£°è°ƒç¬¦å·æ˜ å°„è¡¨
    tone_map = {
        'Ä': 'a', 'Ã¡': 'a', 'Ç': 'a', 'Ã ': 'a',
        'Ä“': 'e', 'Ã©': 'e', 'Ä›': 'e', 'Ã¨': 'e',
        'Ä«': 'i', 'Ã­': 'i', 'Ç': 'i', 'Ã¬': 'i',
        'Å': 'o', 'Ã³': 'o', 'Ç’': 'o', 'Ã²': 'o',
        'Å«': 'u', 'Ãº': 'u', 'Ç”': 'u', 'Ã¹': 'u',
        'Ç–': 'Ã¼', 'Ç˜': 'Ã¼', 'Çš': 'Ã¼', 'Çœ': 'Ã¼', 'Ã¼': 'v',
        'Å„': 'n', 'Åˆ': 'n', 'Ç¹': 'n'
    }
    
    result = ""
    for char in pinyin:
        result += tone_map.get(char, char)
    
    return result

def parse_dict_file(file_path: str) -> List[Tuple[str, str, int]]:
    """è§£æè¯å…¸æ–‡ä»¶ï¼Œè¿”å›(è¯è¯­, æ‹¼éŸ³, è¯é¢‘)çš„åˆ—è¡¨"""
    entries = []
    
    print(f"æ­£åœ¨è§£æè¯å…¸æ–‡ä»¶: {file_path}")
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            line_count = 0
            for line in f:
                line_count += 1
                if line_count % 50000 == 0:
                    print(f"å·²å¤„ç† {line_count} è¡Œ...")
                
                line = line.strip()
                if not line:
                    continue
                
                # è§£ææ ¼å¼ï¼šè¯è¯­\tæ‹¼éŸ³\tè¯é¢‘
                parts = line.split('\t')
                if len(parts) >= 3:
                    word = parts[0].strip()
                    pinyin = parts[1].strip()
                    try:
                        frequency = int(parts[2].strip())
                        
                        # å»é™¤æ‹¼éŸ³å£°è°ƒ
                        pinyin_no_tone = remove_tone_marks(pinyin)
                        
                        entries.append((word, pinyin_no_tone, frequency))
                    except ValueError:
                        print(f"è­¦å‘Šï¼šæ— æ³•è§£æè¯é¢‘ï¼Œè·³è¿‡è¡Œ {line_count}: {line}")
                        continue
    
    except Exception as e:
        print(f"é”™è¯¯ï¼šè§£ææ–‡ä»¶å¤±è´¥ - {e}")
        return []
    
    print(f"è§£æå®Œæˆï¼Œå…±è·å¾— {len(entries)} ä¸ªè¯æ¡")
    return entries

def filter_top_frequency_words(entries: List[Tuple[str, str, int]], percentage: float = 0.5) -> List[Tuple[str, str, int]]:
    """ç­›é€‰è¯é¢‘æœ€é«˜çš„æŒ‡å®šç™¾åˆ†æ¯”çš„è¯è¯­"""
    print(f"æ­£åœ¨ç­›é€‰è¯é¢‘æœ€é«˜çš„ {percentage*100}% è¯è¯­...")
    
    # æŒ‰è¯é¢‘æ’åº
    sorted_entries = sorted(entries, key=lambda x: x[2], reverse=True)
    
    # è®¡ç®—è¦ä¿ç•™çš„è¯è¯­æ•°é‡
    keep_count = int(len(sorted_entries) * percentage)
    
    filtered_entries = sorted_entries[:keep_count]
    
    print(f"ç­›é€‰å®Œæˆï¼Œä» {len(entries)} ä¸ªè¯æ¡ä¸­é€‰æ‹©äº† {len(filtered_entries)} ä¸ªé«˜é¢‘è¯æ¡")
    print(f"è¯é¢‘èŒƒå›´ï¼š{filtered_entries[-1][2]} - {filtered_entries[0][2]}")
    
    return filtered_entries

def build_trie(entries: List[Tuple[str, str, int]]) -> PinyinTrie:
    """æ„å»ºTrieæ ‘"""
    print("æ­£åœ¨æ„å»ºTrieæ ‘...")
    
    trie = PinyinTrie()
    
    for i, (word, pinyin, frequency) in enumerate(entries):
        if i % 10000 == 0:
            print(f"å·²æ’å…¥ {i} ä¸ªè¯æ¡...")
        
        # å°†æ‹¼éŸ³è½¬æ¢ä¸ºå°å†™å¹¶å»é™¤å¤šä½™ç©ºæ ¼
        pinyin_clean = ' '.join(pinyin.lower().split())
        
        # æ’å…¥åˆ°Trieæ ‘
        trie.insert(pinyin_clean, word, frequency)
    
    # è·å–ç»Ÿè®¡ä¿¡æ¯
    node_count, word_count = trie.get_memory_stats()
    print(f"Trieæ ‘æ„å»ºå®Œæˆï¼")
    print(f"ç»Ÿè®¡ä¿¡æ¯ï¼šèŠ‚ç‚¹æ•° = {node_count}, è¯è¯­æ•° = {word_count}")
    
    return trie

def save_trie_to_file(trie: PinyinTrie, output_path: str):
    """ä¿å­˜Trieæ ‘åˆ°æ–‡ä»¶ - ä½¿ç”¨ç‰ˆæœ¬3ç®€åŒ–æ ¼å¼"""
    print(f"æ­£åœ¨ä¿å­˜Trieæ ‘åˆ°æ–‡ä»¶: {output_path}")
    
    try:
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        
        # æ”¶é›†æ‰€æœ‰æ‹¼éŸ³æ¡ç›®
        trie_data = {}
        
        def collect_words(node, current_pinyin=""):
            """é€’å½’æ”¶é›†æ‰€æœ‰è¯è¯­"""
            if node.words:
                if current_pinyin not in trie_data:
                    trie_data[current_pinyin] = []
                for word_item in node.words:
                    trie_data[current_pinyin].append({
                        'word': word_item.word,
                        'frequency': word_item.frequency
                    })
            
            for char, child_node in node.children.items():
                collect_words(child_node, current_pinyin + char)
        
        collect_words(trie.root)
        
        with open(output_path, 'wb') as f:
            # å†™å…¥ç‰ˆæœ¬å·ï¼ˆä½¿ç”¨LITTLE_ENDIANï¼‰
            f.write(struct.pack('<i', 3))  # ç‰ˆæœ¬3ï¼Œç®€åŒ–æ ¼å¼ï¼ŒLITTLE_ENDIAN
            
            # å†™å…¥æ•°æ®æ¡ç›®æ•°é‡
            f.write(struct.pack('<i', len(trie_data)))
            
            # å†™å…¥æ¯ä¸ªæ¡ç›®
            for pinyin, words in trie_data.items():
                # å†™å…¥æ‹¼éŸ³é•¿åº¦å’Œæ‹¼éŸ³
                pinyin_bytes = pinyin.encode('utf-8')
                f.write(struct.pack('<i', len(pinyin_bytes)))
                f.write(pinyin_bytes)
                
                # å†™å…¥è¯è¯­æ•°é‡
                f.write(struct.pack('<i', len(words)))
                
                # å†™å…¥æ¯ä¸ªè¯è¯­
                for word_item in words:
                    word_bytes = word_item['word'].encode('utf-8')
                    f.write(struct.pack('<i', len(word_bytes)))
                    f.write(word_bytes)
                    f.write(struct.pack('<i', word_item['frequency']))
        
        # éªŒè¯æ–‡ä»¶
        file_size = os.path.getsize(output_path)
        print(f"æ–‡ä»¶ä¿å­˜æˆåŠŸï¼æ–‡ä»¶å¤§å°: {file_size} å­—èŠ‚ ({file_size/1024/1024:.2f} MB)")
        
        return True
        
    except Exception as e:
        print(f"é”™è¯¯ï¼šä¿å­˜æ–‡ä»¶å¤±è´¥ - {e}")
        return False

def verify_trie_file(file_path: str) -> bool:
    """éªŒè¯ç”Ÿæˆçš„Trieæ–‡ä»¶æ˜¯å¦å¯ç”¨ - ç‰ˆæœ¬3æ ¼å¼"""
    print(f"æ­£åœ¨éªŒè¯Trieæ–‡ä»¶: {file_path}")
    
    try:
        with open(file_path, 'rb') as f:
            # è¯»å–ç‰ˆæœ¬å·
            version_bytes = f.read(4)
            if len(version_bytes) != 4:
                print("é”™è¯¯ï¼šæ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®ï¼Œæ— æ³•è¯»å–ç‰ˆæœ¬å·")
                return False
            
            version = struct.unpack('<i', version_bytes)[0]
            print(f"æ–‡ä»¶ç‰ˆæœ¬å·: {version}")
            
            if version != 3:
                print(f"é”™è¯¯ï¼šä¸æ”¯æŒçš„ç‰ˆæœ¬å· {version}ï¼ŒæœŸæœ›ç‰ˆæœ¬3")
                return False
            
            # è¯»å–æ¡ç›®æ•°é‡
            count_bytes = f.read(4)
            if len(count_bytes) != 4:
                print("é”™è¯¯ï¼šæ— æ³•è¯»å–æ¡ç›®æ•°é‡")
                return False
            
            count = struct.unpack('<i', count_bytes)[0]
            print(f"æ‹¼éŸ³æ¡ç›®æ•°é‡: {count}")
            
            if count <= 0:
                print("é”™è¯¯ï¼šæ¡ç›®æ•°é‡æ— æ•ˆ")
                return False
            
            print(f"éªŒè¯æˆåŠŸï¼æ–‡ä»¶åŒ…å« {count} ä¸ªæ‹¼éŸ³æ¡ç›®")
            return True
            
    except Exception as e:
        print(f"é”™è¯¯ï¼šéªŒè¯æ–‡ä»¶å¤±è´¥ - {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ç¥è¿¹è¾“å…¥æ³• - Baseè¯å…¸Trieé¢„ç¼–è¯‘æ„å»ºå·¥å…·")
    print("=" * 60)
    
    # æ–‡ä»¶è·¯å¾„
    input_file = "app/src/main/assets/cn_dicts/base.dict.yaml"
    output_file = "app/src/main/assets/trie/base_trie.dat"
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(input_file):
        print(f"é”™è¯¯ï¼šè¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨ - {input_file}")
        return 1
    
    try:
        # æ­¥éª¤1ï¼šè§£æè¯å…¸æ–‡ä»¶
        entries = parse_dict_file(input_file)
        if not entries:
            print("é”™è¯¯ï¼šæ— æ³•è§£æè¯å…¸æ–‡ä»¶æˆ–æ–‡ä»¶ä¸ºç©º")
            return 1
        
        # æ­¥éª¤2ï¼šç­›é€‰é«˜é¢‘è¯è¯­ï¼ˆ50%ï¼‰
        filtered_entries = filter_top_frequency_words(entries, 0.5)
        if not filtered_entries:
            print("é”™è¯¯ï¼šç­›é€‰åæ²¡æœ‰è¯è¯­")
            return 1
        
        # æ­¥éª¤3ï¼šæ„å»ºTrieæ ‘
        trie = build_trie(filtered_entries)
        if trie.is_empty():
            print("é”™è¯¯ï¼šæ„å»ºçš„Trieæ ‘ä¸ºç©º")
            return 1
        
        # æ­¥éª¤4ï¼šä¿å­˜Trieæ ‘
        if not save_trie_to_file(trie, output_file):
            print("é”™è¯¯ï¼šä¿å­˜Trieæ–‡ä»¶å¤±è´¥")
            return 1
        
        # æ­¥éª¤5ï¼šéªŒè¯ç”Ÿæˆçš„æ–‡ä»¶
        if not verify_trie_file(output_file):
            print("é”™è¯¯ï¼šç”Ÿæˆçš„æ–‡ä»¶éªŒè¯å¤±è´¥")
            return 1
        
        print("\n" + "=" * 60)
        print("âœ… Baseè¯å…¸Trieé¢„ç¼–è¯‘æ–‡ä»¶æ„å»ºæˆåŠŸï¼")
        print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {output_file}")
        print("=" * 60)
        
        return 0
        
    except Exception as e:
        print(f"é”™è¯¯ï¼šç¨‹åºæ‰§è¡Œå¤±è´¥ - {e}")
        import traceback
        traceback.print_exc()
        return 1

if __name__ == "__main__":
    sys.exit(main()) 