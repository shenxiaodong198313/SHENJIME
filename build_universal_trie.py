#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç¥è¿¹è¾“å…¥æ³• - é€šç”¨è¯å…¸Trieæ„å»ºå·¥å…·
æ”¯æŒæ„å»ºå„ç§ç±»å‹çš„è¯å…¸æ–‡ä»¶
"""

import os
import sys
import struct
from typing import Dict, List, Tuple

def remove_tone_marks(pinyin: str) -> str:
    """å»é™¤æ‹¼éŸ³ä¸­çš„å£°è°ƒç¬¦å·"""
    tone_map = {
        'Ä': 'a', 'Ã¡': 'a', 'Ç': 'a', 'Ã ': 'a',
        'Ä“': 'e', 'Ã©': 'e', 'Ä›': 'e', 'Ã¨': 'e',
        'Ä«': 'i', 'Ã­': 'i', 'Ç': 'i', 'Ã¬': 'i',
        'Å': 'o', 'Ã³': 'o', 'Ç’': 'o', 'Ã²': 'o',
        'Å«': 'u', 'Ãº': 'u', 'Ç”': 'u', 'Ã¹': 'u',
        'Ç–': 'Ã¼', 'Ç˜': 'Ã¼', 'Çš': 'Ã¼', 'Çœ': 'Ã¼', 'Ã¼': 'v',
        'Å„': 'n', 'Åˆ': 'n', 'Ç¹': 'n'
    }
    
    result = ""
    for char in pinyin:
        result += tone_map.get(char, char)
    
    return result

def parse_dict_file(file_path: str, percentage: float = 0.3) -> List[Tuple[str, str, int]]:
    """è§£æè¯å…¸æ–‡ä»¶å¹¶ç­›é€‰æŒ‡å®šæ¯”ä¾‹çš„é«˜é¢‘è¯æ¡"""
    entries = []
    
    print(f"æ­£åœ¨è§£æè¯å…¸æ–‡ä»¶: {file_path}")
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            line_count = 0
            for line in f:
                line_count += 1
                if line_count % 25000 == 0:
                    print(f"å·²å¤„ç† {line_count} è¡Œ...")
                
                line = line.strip()
                if not line:
                    continue
                
                parts = line.split('\t')
                if len(parts) >= 3:
                    word = parts[0].strip()
                    pinyin = parts[1].strip()
                    
                    if not pinyin or len(pinyin.strip()) == 0:
                        continue
                    
                    try:
                        frequency = int(parts[2].strip())
                        pinyin_no_tone = remove_tone_marks(pinyin)
                        entries.append((word, pinyin_no_tone, frequency))
                    except ValueError:
                        continue
    
    except Exception as e:
        print(f"é”™è¯¯ï¼šè§£ææ–‡ä»¶å¤±è´¥ - {e}")
        return []
    
    print(f"è§£æå®Œæˆï¼Œå…±è·å¾— {len(entries)} ä¸ªè¯æ¡")
    
    # æŒ‰è¯é¢‘æ’åºå¹¶ç­›é€‰é«˜é¢‘è¯
    print(f"æ­£åœ¨ç­›é€‰è¯é¢‘æœ€é«˜çš„ {percentage*100}% è¯è¯­...")
    sorted_entries = sorted(entries, key=lambda x: x[2], reverse=True)
    keep_count = int(len(sorted_entries) * percentage)
    filtered_entries = sorted_entries[:keep_count]
    
    print(f"ç­›é€‰å®Œæˆï¼Œä» {len(entries)} ä¸ªè¯æ¡ä¸­é€‰æ‹©äº† {len(filtered_entries)} ä¸ªé«˜é¢‘è¯æ¡")
    if filtered_entries:
        print(f"è¯é¢‘èŒƒå›´ï¼š{filtered_entries[-1][2]} - {filtered_entries[0][2]}")
    
    return filtered_entries

def build_trie_data(entries: List[Tuple[str, str, int]], max_words_per_pinyin: int = 40) -> Dict:
    """æ„å»ºTrieæ•°æ®ç»“æ„"""
    print("æ­£åœ¨æ„å»ºTrieæ•°æ®...")
    
    trie_data = {}
    
    for i, (word, pinyin, frequency) in enumerate(entries):
        if i % 5000 == 0:
            print(f"å·²å¤„ç† {i} ä¸ªè¯æ¡...")
        
        # æ¸…ç†æ‹¼éŸ³æ ¼å¼
        pinyin_clean = ' '.join(pinyin.lower().split())
        
        # å­˜å‚¨åˆ°å­—å…¸ä¸­
        if pinyin_clean not in trie_data:
            trie_data[pinyin_clean] = []
        
        trie_data[pinyin_clean].append({
            'word': word,
            'frequency': frequency
        })
    
    # å¯¹æ¯ä¸ªæ‹¼éŸ³çš„è¯è¯­æŒ‰é¢‘ç‡æ’åºå¹¶é™åˆ¶æ•°é‡
    total_words = 0
    for pinyin in trie_data:
        trie_data[pinyin].sort(key=lambda x: x['frequency'], reverse=True)
        trie_data[pinyin] = trie_data[pinyin][:max_words_per_pinyin]
        total_words += len(trie_data[pinyin])
    
    print(f"Trieæ„å»ºå®Œæˆï¼åŒ…å« {len(trie_data)} ä¸ªæ‹¼éŸ³æ¡ç›®ï¼Œæ€»è¯æ•°: {total_words}")
    return trie_data

def save_trie_data_file(trie_data: Dict, output_path: str) -> bool:
    """ä¿å­˜Trieæ•°æ®æ–‡ä»¶"""
    print(f"æ­£åœ¨ä¿å­˜Trieæ•°æ®åˆ°æ–‡ä»¶: {output_path}")
    
    try:
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        
        with open(output_path, 'wb') as f:
            # å†™å…¥ç‰ˆæœ¬å·ï¼ˆä½¿ç”¨LITTLE_ENDIANï¼‰
            f.write(struct.pack('<i', 3))  # ç‰ˆæœ¬3ï¼Œç®€åŒ–æ ¼å¼ï¼ŒLITTLE_ENDIAN
            
            # å†™å…¥æ•°æ®æ¡ç›®æ•°é‡
            f.write(struct.pack('<i', len(trie_data)))
            
            # å†™å…¥æ¯ä¸ªæ¡ç›®
            for pinyin, words in trie_data.items():
                # å†™å…¥æ‹¼éŸ³é•¿åº¦å’Œæ‹¼éŸ³
                pinyin_bytes = pinyin.encode('utf-8')
                f.write(struct.pack('<i', len(pinyin_bytes)))
                f.write(pinyin_bytes)
                
                # å†™å…¥è¯è¯­æ•°é‡
                f.write(struct.pack('<i', len(words)))
                
                # å†™å…¥æ¯ä¸ªè¯è¯­
                for word_item in words:
                    word_bytes = word_item['word'].encode('utf-8')
                    f.write(struct.pack('<i', len(word_bytes)))
                    f.write(word_bytes)
                    f.write(struct.pack('<i', word_item['frequency']))
        
        file_size = os.path.getsize(output_path)
        print(f"æ–‡ä»¶ä¿å­˜æˆåŠŸï¼æ–‡ä»¶å¤§å°: {file_size} å­—èŠ‚ ({file_size/1024/1024:.2f} MB)")
        
        return True
        
    except Exception as e:
        print(f"é”™è¯¯ï¼šä¿å­˜æ–‡ä»¶å¤±è´¥ - {e}")
        return False

def build_dict_trie(dict_name: str, percentage: float = 0.3, max_words: int = 40):
    """æ„å»ºæŒ‡å®šè¯å…¸çš„Trieæ–‡ä»¶"""
    input_path = f"app/src/main/assets/cn_dicts/{dict_name}.dict.yaml"
    output_path = f"app/src/main/assets/trie/{dict_name}_trie.dat"
    
    print("=" * 60)
    print(f"ç¥è¿¹è¾“å…¥æ³• - {dict_name}è¯å…¸Trieæ„å»ºå·¥å…·")
    print("=" * 60)
    print(f"è¾“å…¥æ–‡ä»¶: {input_path}")
    print(f"è¾“å‡ºæ–‡ä»¶: {output_path}")
    print(f"ç­–ç•¥: ä¿ç•™{percentage*100}%é«˜é¢‘è¯ï¼Œæ¯ä¸ªæ‹¼éŸ³æœ€å¤š{max_words}ä¸ªè¯")
    print("=" * 60)
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(input_path):
        print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_path}")
        return False
    
    # è§£æå¹¶ç­›é€‰è¯å…¸æ–‡ä»¶
    entries = parse_dict_file(input_path, percentage)
    if not entries:
        print("âŒ è§£æè¯å…¸æ–‡ä»¶å¤±è´¥")
        return False
    
    # æ„å»ºTrieæ•°æ®
    trie_data = build_trie_data(entries, max_words)
    if not trie_data:
        print("âŒ æ„å»ºTrieæ•°æ®å¤±è´¥")
        return False
    
    # ä¿å­˜æ–‡ä»¶
    if not save_trie_data_file(trie_data, output_path):
        print("âŒ ä¿å­˜æ–‡ä»¶å¤±è´¥")
        return False
    
    print("=" * 60)
    print(f"âœ… {dict_name}è¯å…¸Trieæ–‡ä»¶æ„å»ºæˆåŠŸï¼")
    print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {output_path}")
    print("=" * 60)
    
    return True

def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python build_universal_trie.py <è¯å…¸åç§°> [ç­›é€‰æ¯”ä¾‹] [æ¯æ‹¼éŸ³æœ€å¤§è¯æ•°]")
        print("ç¤ºä¾‹: python build_universal_trie.py correlation 0.3 40")
        print("å¯ç”¨è¯å…¸: correlation, associational, place, people, poetry, corrections, compatible")
        return 1
    
    dict_name = sys.argv[1]
    percentage = float(sys.argv[2]) if len(sys.argv) > 2 else 0.3
    max_words = int(sys.argv[3]) if len(sys.argv) > 3 else 40
    
    success = build_dict_trie(dict_name, percentage, max_words)
    return 0 if success else 1

if __name__ == "__main__":
    exit(main()) 